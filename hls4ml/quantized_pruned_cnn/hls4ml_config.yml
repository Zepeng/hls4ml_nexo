Backend: Vivado
Board: null
ClockPeriod: 5
HLSConfig:
  LayerName:
    add_3:
      Precision: ap_fixed<16,6>
    add_4:
      Precision: ap_fixed<16,6>
    add_5:
      Precision: ap_fixed<16,6>
    input_2:
      Precision:
        result: ap_fixed<16,6>
    q_activation:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_1:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_10:
      Precision:
        result: ap_fixed<10,5>
      ReuseFactor: 1
    q_activation_11:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_2:
      Precision:
        result: ap_fixed<10,5>
      ReuseFactor: 1
    q_activation_3:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_4:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_5:
      Precision:
        result: ap_fixed<10,5>
      ReuseFactor: 1
    q_activation_6:
      Precision:
        result: ap_fixed<10,5>
      ReuseFactor: 1
    q_activation_7:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_8:
      Precision:
        result: ap_ufixed<16,12>
      ReuseFactor: 1
    q_activation_9:
      Precision:
        result: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_1:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm_1:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm_2:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm_3:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm_4:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm_5:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_conv2d_batchnorm_6:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    q_dense:
      Precision:
        bias: ap_fixed<10,5>
        weight: ap_fixed<10,5>
      ReuseFactor: 1
    sigmoid:
      Precision: ap_fixed<16,6>
      ReuseFactor: 1
      table_size: 1024
      table_t: ap_fixed<18,8>
  Model:
    Precision: ap_fixed<16,6>
    ReuseFactor: 1
    Strategy: Latency
IOType: io_stream
KerasModel: !keras_model 'quantized_pruned_cnn//keras_model.h5'
OutputDir: quantized_pruned_cnn/
ProjectName: myproject
Stamp: FdcF9130
XilinxPart: xcu250-figd2104-2L-e
