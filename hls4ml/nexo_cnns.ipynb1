{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Convolutional Neural Networks in hls4ml<br>\n","<br>\n","In this notebook we will use a simple convolutional neural network for e/gamma classification in nEXO experiment.<br>\n","<br>\n","The dataset is constructed with charge readout simulation of electron and gamma events with energies between 1 and 3 MeV. An electron event has a label of 1, and a gamma event has a label of 0.<br>\n","<br>\n","Each event has a size of 200\\*255\\*2. "]},{"cell_type":"markdown","metadata":{},"source":["## Start with the neccessary imports"]},{"cell_type":"markdown","metadata":{},"source":["In[1]:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import tensorflow as tf\n","import tensorflow_datasets as tfds"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load custom nEXO dataset<br>\n","<br>\n","In this part we will fetch the trainining, validation and test dataset using a custom dataloader to load nEXO dataset."]},{"cell_type":"markdown","metadata":{},"source":["In[2]:"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["n_classes = 2\n","input_shape = [200, 255, 2]\n","batch_size = 60\n","from data_loader import nEXODataset\n","from tensorflow.data import Dataset\n","csv_train = '/scratch/zel032/DatasetFromMin/nexo_train.csv'\n","csv_test = '/scratch/zel032/DatasetFromMin/nexo_valid.csv'\n","h5file = '/scratch/zel032/DatasetFromMin/nexo.h5'\n","# load dataset\n","train_dg = nEXODataset('train',h5file,csv_train)\n","test_dg = nEXODataset('test',h5file,csv_test)\n","train_ds = Dataset.from_generator(train_dg, output_types = (tf.float32, tf.int64) , output_shapes = (tf.TensorShape(input_shape),tf.TensorShape([])))\n","test_ds = Dataset.from_generator(test_dg, output_types = (tf.float32, tf.int64) , output_shapes = (tf.TensorShape(input_shape),tf.TensorShape([])))\n","train_ds = train_ds.interleave(lambda x, y: tf.data.Dataset.from_tensors((x,y)), cycle_length=4, block_length=16)\n","test_ds = test_ds.interleave(lambda x, y: tf.data.Dataset.from_tensors((x,y)), cycle_length=4, block_length=16)"]},{"cell_type":"markdown","metadata":{},"source":["In[3]:"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(200, 255, 2) (2,) <class 'tensorflow.python.framework.ops.Tensor'>\n","X train batch shape = (60, 200, 255, 2), Y train batch shape = (60, 2) \n","(200, 255, 2) (2,) <class 'tensorflow.python.framework.ops.Tensor'>\n"]}],"source":["def preprocess(image, label,nclasses=2):\n","    #image = tf.cast(image, tf.float32) / 256.\n","    label = tf.one_hot(tf.squeeze(label), nclasses)\n","    print(image.shape, label.shape, type(label))\n","    return image, label\n","train_data = train_ds.map(preprocess,n_classes) #Get dataset as image and one-hot encoded labels, divided by max RGB   \n","train_data = train_data.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","for example in train_data.take(1):\n","    break\n","print(\"X train batch shape = {}, Y train batch shape = {} \".format(example[0].shape, example[1].shape))\n","val_data = test_ds.map(preprocess,n_classes)    \n","val_data = val_data.batch(batch_size)\n","val_data = val_data.prefetch(tf.data.experimental.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["In[4]:"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the model<br>\n","<br>\n","We then need to define a model. For the lowest possible latency, each layer should have a maximum number of trainable parameters of 4096. This is due to fixed limits in the Vivado compiler, beyond which maximally unrolled (=parallel) compilation will fail. This will allow us to use `strategy = 'latency'` in the hls4ml part, rather than `strategy = 'resource'`, in turn resulting in lower latency"]},{"cell_type":"markdown","metadata":{},"source":["In[5]:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import resnet_v1_eembc\n","kwargs = {'input_shape': input_shape,\n","            'num_classes': n_classes,\n","            'avg_pooling': True \n","        }\n","model_name = 'resnet_v1_eembc'\n","model = getattr(resnet_v1_eembc, model_name)(**kwargs)"]},{"cell_type":"markdown","metadata":{},"source":["Lets check if this model can be implemented completely unrolled (=parallel)"]},{"cell_type":"markdown","metadata":{},"source":["In[6]:"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["conv2d_9: 288\n","conv2d_10: 2304\n","conv2d_11: 2304\n","conv2d_12: 4608\n","Layer conv2d_12 is too large (4608), are you sure you want to train?\n","conv2d_13: 9216\n","Layer conv2d_13 is too large (9216), are you sure you want to train?\n","conv2d_14: 512\n","conv2d_15: 18432\n","Layer conv2d_15 is too large (18432), are you sure you want to train?\n","conv2d_16: 36864\n","Layer conv2d_16 is too large (36864), are you sure you want to train?\n","conv2d_17: 2048\n","dense_1: 128\n"]}],"source":["for layer in model.layers:\n","    if layer.__class__.__name__ in ['Conv2D', 'Dense']:\n","        w = layer.get_weights()[0]\n","        layersize = np.prod(w.shape)\n","        print(\"{}: {}\".format(layer.name,layersize)) # 0 = weights, 1 = biases\n","        if (layersize > 4096): # assuming that shape[0] is batch, i.e., 'None'\n","            print(\"Layer {} is too large ({}), are you sure you want to train?\".format(layer.name,layersize))"]},{"cell_type":"markdown","metadata":{},"source":["Looks good! It's below the Vivado-enforced unroll limit of 4096.<br>\n","<br>\n","## Prune dense and convolutional layers<br>\n","Since we've seen in the previous notebooks that pruning can be done at no accuracy cost, let's prune the convolutional and dense layers to 50% sparsity, skipping the output layer"]},{"cell_type":"markdown","metadata":{},"source":["In[7]:"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training steps per epoch is 166\n"]}],"source":["import tensorflow_model_optimization as tfmot\n","from tensorflow_model_optimization.sparsity import keras as sparsity\n","from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n","NSTEPS = 10000  // batch_size #90% train, 10% validation in 10-fold cross validation\n","print('Number of training steps per epoch is {}'.format(NSTEPS))\n","def pruneFunction(layer):\n","    pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity = 0.0,\n","                                                                   final_sparsity = 0.50, \n","                                                                   begin_step = NSTEPS*2, \n","                                                                   end_step = NSTEPS*10, \n","                                                                   frequency = NSTEPS)\n","                     }\n","    if isinstance(layer, tf.keras.layers.Conv2D):\n","        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n","    if isinstance(layer, tf.keras.layers.Dense) and layer.name!='output_dense':\n","        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)  \n","    return layer\n","model_pruned = tf.keras.models.clone_model( model ) #, clone_function=pruneFunction)"]},{"cell_type":"markdown","metadata":{},"source":["## Train baseline<br>\n","<br>\n","We're now ready to train the model! We defined the batch size and n epochs above. We won't use callbacks that store the best weights only, since this might select a weight configuration that has not yet reached 50% sparsity."]},{"cell_type":"markdown","metadata":{},"source":["In[8]:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["train = False # True if you want to retrain, false if you want to load a previsously trained model\n","n_epochs = 10 \n","if train:\n","    \n","    LOSS        = tf.keras.losses.BinaryCrossentropy()\n","    OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n","    model_pruned.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n","    callbacks = [\n","            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n","            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n","            pruning_callbacks.UpdatePruningStep()\n","            ] \n","    start = time.time()\n","    model_pruned.fit(train_data,\n","                     epochs = n_epochs,\n","                     validation_data = val_data,\n","                     callbacks = callbacks)   \n","    end = time.time()\n","    print('It took {} minutes to train Keras model'.format( (end - start)/60.))\n","    \n","    model_pruned.save('pruned_cnn_model.h5')\n","else:\n","    from qkeras.utils import _add_supported_quantized_objects\n","    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n","    \n","    co = {}\n","    _add_supported_quantized_objects(co)\n","    co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n","    model_pruned = tf.keras.models.load_model('pruned_cnn_model.h5', custom_objects=co)"]},{"cell_type":"markdown","metadata":{},"source":["## Quantization and the fused Conv2D+BatchNormalization layer in QKeras<br>\n","Let's now create a pruned an quantized model using QKeras. For this, we will use a fused Convolutional and BatchNormalization (BN) layer from QKeras, which will further speed up the implementation when we implement the model using hls4ml. <br>\n","There is currently no fused Dense+BatchNoralization layer available in QKeras, so we'll use Keras BatchNormalization when BN follows a Dense layer for now. We'll use the same precision everywhere, namely a bit width of 6 and 0 integer bits (this will be implemented as``<6,1>`` in hls4ml, due to the missing sign-bit). For now, make sure to set ```use_bias=True``` in ```QConv2DBatchnorm``` to avoid problems during synthesis."]},{"cell_type":"markdown","metadata":{},"source":["In[11]:"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"('Keyword argument not understood:', 'quantizer')","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m'\u001b[39m: input_shape,\n\u001b[1;32m      4\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m: n_classes,\n\u001b[1;32m      5\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mavg_pooling\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mactivation_int_bits\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m12\u001b[39m\n\u001b[1;32m     10\u001b[0m         }\n\u001b[1;32m     11\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresnet_v1_eembc_quantized\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m qmodel \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(resnet_v1_eembc, model_name)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     13\u001b[0m qmodel\u001b[39m.\u001b[39msummary()\n","File \u001b[0;32m/scratch/zel032/hls4ml-tutorial/resnet_v1_eembc.py:367\u001b[0m, in \u001b[0;36mresnet_v1_eembc_quantized\u001b[0;34m(input_shape, num_classes, l1p, l2p, num_filters, kernel_sizes, strides, logit_total_bits, logit_int_bits, activation_total_bits, activation_int_bits, alpha, use_stochastic_rounding, logit_quantizer, activation_quantizer, skip, avg_pooling, final_activation)\u001b[0m\n\u001b[1;32m    365\u001b[0m pool_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mamin(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:\u001b[39m3\u001b[39m]))\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m pool_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m avg_pooling:\n\u001b[0;32m--> 367\u001b[0m     x \u001b[39m=\u001b[39m QAveragePooling2D(pool_size\u001b[39m=\u001b[39;49mpool_size, quantizer\u001b[39m=\u001b[39;49mlogit_quantizer)(x)\n\u001b[1;32m    369\u001b[0m y \u001b[39m=\u001b[39m Flatten()(x)\n\u001b[1;32m    370\u001b[0m \u001b[39m# Changed output to separate QDense but did not quantize softmax as specified\u001b[39;00m\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/qkeras/qpooling.py:48\u001b[0m, in \u001b[0;36mQAveragePooling2D.__init__\u001b[0;34m(self, pool_size, strides, padding, data_format, average_quantizer, activation, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m activation\n\u001b[0;32m---> 48\u001b[0m \u001b[39msuper\u001b[39;49m(QAveragePooling2D, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     49\u001b[0m     pool_size\u001b[39m=\u001b[39;49mpool_size, strides\u001b[39m=\u001b[39;49mstrides, padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m     50\u001b[0m     data_format\u001b[39m=\u001b[39;49mdata_format, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras/layers/pooling/average_pooling2d.py:136\u001b[0m, in \u001b[0;36mAveragePooling2D.__init__\u001b[0;34m(self, pool_size, strides, padding, data_format, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    130\u001b[0m     pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    135\u001b[0m ):\n\u001b[0;32m--> 136\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    137\u001b[0m         tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mavg_pool,\n\u001b[1;32m    138\u001b[0m         pool_size\u001b[39m=\u001b[39;49mpool_size,\n\u001b[1;32m    139\u001b[0m         strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m    140\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m    141\u001b[0m         data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    143\u001b[0m     )\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras/layers/pooling/base_pooling2d.py:63\u001b[0m, in \u001b[0;36mPooling2D.__init__\u001b[0;34m(self, pool_function, pool_size, strides, padding, data_format, name, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     54\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     55\u001b[0m     pool_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     62\u001b[0m ):\n\u001b[0;32m---> 63\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name\u001b[39m=\u001b[39;49mname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m data_format \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         data_format \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mimage_data_format()\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras/engine/base_layer.py:340\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m allowed_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    330\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_dim\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimplementation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m }\n\u001b[1;32m    339\u001b[0m \u001b[39m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m generic_utils\u001b[39m.\u001b[39;49mvalidate_kwargs(kwargs, allowed_kwargs)\n\u001b[1;32m    342\u001b[0m \u001b[39m# Mutable properties\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    346\u001b[0m     \u001b[39misinstance\u001b[39m(trainable, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    347\u001b[0m     \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m ):\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras/utils/generic_utils.py:515\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39mfor\u001b[39;00m kwarg \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m kwarg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m--> 515\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(error_message, kwarg)\n","\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'quantizer')"]}],"source":["from qkeras import QActivation\n","from qkeras import QDense, QConv2DBatchnorm\n","kwargs = {'input_shape': input_shape,\n","          'num_classes': n_classes,\n","          'avg_pooling': True,\n","          'logit_total_bits': 10,\n","          'logit_int_bits': 4,\n","          'activation_total_bits': 16,\n","          'activation_int_bits':12\n","        }\n","model_name = 'resnet_v1_eembc_quantized'\n","qmodel = getattr(resnet_v1_eembc, model_name)(**kwargs)\n","qmodel.summary()"]},{"cell_type":"markdown","metadata":{},"source":["In[12]:"]},{"cell_type":"markdown","metadata":{},"source":["Print the quantized layers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from qkeras.autoqkeras.utils import print_qmodel_summary\n","print_qmodel_summary(qmodel)        "]},{"cell_type":"markdown","metadata":{},"source":["You see that a bias quantizer is defined, although we are not using a bias term for the layers. This is set automatically by QKeras. In addition, you'll note that ``alpha='1'``. This sets the weight scale per channel to 1 (no scaling). The default is ``alpha='auto_po2'``, which sets the weight scale per channel to be a power-of-2, such that an actual hardware implementation can be performed by just shifting the result of the convolutional/dense layer to the right or left by checking the sign of the scale and then taking the log2 of the scale.<br>\n","<br>\n","Let's now prune and train this model! If you want, you can also train the unpruned version, ``qmodel`` and see how the performance compares. We will stick to the pruned one here. Again, we do not use a model checkpoint which stores the best weights, in order to ensure the model is trained to the desired sparsity."]},{"cell_type":"markdown","metadata":{},"source":["In[13]:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'qmodel' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qmodel_pruned \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mclone_model( qmodel) \u001b[39m#, clone_function=pruneFunction)\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'qmodel' is not defined"]}],"source":["qmodel_pruned = tf.keras.models.clone_model( qmodel) #, clone_function=pruneFunction)"]},{"cell_type":"markdown","metadata":{},"source":["In[14]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train = True \n","if train:\n","    LOSS        = tf.keras.losses.BinaryCrossentropy()\n","    OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=1E-2, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True) \n","    qmodel_pruned.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n","    callbacks = [\n","            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n","            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n","            pruning_callbacks.UpdatePruningStep()\n","            ]  \n","    start = time.time()\n","    history = qmodel_pruned.fit(train_data,\n","                          epochs = n_epochs,\n","                          validation_data = val_data,\n","                          callbacks = callbacks, \n","                          verbose=1)     \n","    end = time.time()\n","    print('\\n It took {} minutes to train!\\n'.format( (end - start)/60.))\n","    qmodel_pruned.save('quantized_pruned_cnn_model.h5')\n","else:\n","    from qkeras.utils import _add_supported_quantized_objects\n","    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n","    \n","    co = {}\n","    _add_supported_quantized_objects(co)\n","    co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n","    qmodel_pruned = tf.keras.models.load_model('quantized_pruned_cnn_model.h5', custom_objects=co)"]},{"cell_type":"markdown","metadata":{},"source":["We note that training a model quantization aware, takes around twice as long as when not quantizing during training!<br>\n","The validation accuracy is very similar to that of the floating point model equivalent, despite containing significantly less information <br>\n","<br>\n","## Performance<br>\n","Let's look at some ROC curves to compare the performance. Lets choose a few numbers so it doesn't get confusing. Feel free to change the numbers in ``labels``."]},{"cell_type":"markdown","metadata":{},"source":["In[15]:"]},{"cell_type":"markdown","metadata":{},"source":["For  testing, we get the full dataset in memory as it's rather small.<br>\n","We fetch it as numpy arrays to have access to labels and images separately"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["iterator = iter(val_data)\n","X_test, Y_test = next(iterator)\n","#X_test, Y_test = tfds.as_numpy(val_data)\n","#X_test, Y_test = preprocess(X_test, Y_test,nclasses=n_classes)\n","print(\"X test batch shape = {}, Y test batch shape = {} \".format(X_test.shape,Y_test.shape))\n","#iterator = iter(val_data)\n","#X_test, Y_test = val_data #next(iterator)\n","#X_test, Y_test = preprocess(X_test, Y_test,nclasses=n_classes)\n","predict_baseline    = model_pruned.predict(X_test)\n","#print(predict_baseline)\n","test_score_baseline = model_pruned.evaluate(X_test, Y_test)\n","predict_qkeras    = qmodel_pruned.predict(X_test)\n","print(predict_qkeras)\n","test_score_qkeras = qmodel_pruned.evaluate(X_test, Y_test)\n","print('Keras accuracy = {} , QKeras 6-bit accuracy = {}'.format(test_score_baseline[1],test_score_qkeras[1]))"]},{"cell_type":"markdown","metadata":{},"source":["In[19]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn import metrics\n","labels=['%i'%nr for nr in range (0,n_classes)] # If you want to look at all the labels\n","# labels = ['0','1','9'] # Look at only a few labels, here for digits 0, 1 and 9\n","print('Plotting ROC for labels {}'.format(labels))\n","df = pd.DataFrame()\n","df_q = pd.DataFrame()\n","fpr  = {}\n","tpr  = {}\n","auc1 = {}\n","fpr_q  = {}\n","tpr_q  = {}\n","auc1_q = {}\n","#get_ipython().run_line_magic('matplotlib', 'inline')\n","colors  = ['#67001f','#b2182b','#d6604d','#f4a582','#fddbc7','#d1e5f0','#92c5de','#4393c3','#2166ac','#053061']\n","fig, ax = plt.subplots(figsize=(10, 10))\n","for i, label in enumerate(labels):\n","    print(label, Y_test)\n","    df[label] =  Y_test[:,int(label)]\n","    df[label + '_pred'] = predict_baseline[:,int(label)]\n","    fpr[label], tpr[label], threshold = metrics.roc_curve(df[label],df[label+'_pred'])\n","    auc1[label] = metrics.auc(fpr[label], tpr[label])\n","    \n","    #df_q[label] = Y_test[:,int(label)]\n","    #df_q[label + '_pred'] = predict_qkeras[:,int(label)]\n","    #fpr_q[label], tpr_q[label], threshold_q = metrics.roc_curve(df_q[label],df_q[label+'_pred'])\n","    #auc1_q[label] = metrics.auc(fpr_q[label], tpr_q[label])\n","    \n","    #plt.plot(fpr[label],tpr[label]    ,label=r'{}, AUC Keras = {:.1f}% AUC QKeras = {:.1f}%)'.format(label,auc1[label]*100,auc1_q[label]*100), linewidth=1.5,c=colors[i],linestyle='solid')\n","    #plt.plot(fpr_q[label],tpr_q[label], linewidth=1.5,c=colors[i],linestyle='dotted')\n","plt.semilogx()\n","plt.ylabel(\"True Positive Rate\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.xlim(0.01,1.)\n","plt.ylim(0.5,1.1)\n","plt.legend(loc='lower right')\n","#plt.figtext(0.2, 0.83,r'Accuracy Keras = {:.1f}% QKeras 8-bit = {:.1f}%'.format(test_score_baseline[1]*100,test_score_qkeras[1]*100), wrap=True, horizontalalignment='left',verticalalignment='center')\n","from matplotlib.lines import Line2D\n","lines = [Line2D([0], [0], ls='-'),\n","         Line2D([0], [0], ls='--')]\n","from matplotlib.legend import Legend\n","leg = Legend(ax, lines, labels=['Keras', 'QKeras'],\n","            loc='lower right', frameon=False)\n","ax.add_artist(leg)"]},{"cell_type":"markdown","metadata":{},"source":["The difference in AUC between the fp32 Keras model and the 8-bit QKeras model, is small, as we have seen for the previous examples. You can find a bonus exercise below, **Bonus: Automatic quantization**, where we'll use AutoQKeras to find the best heterogeneously quantized model, given a set of resource and accuracy constriants.<br>\n","### Check sparsity<br>\n","Let's also check the per-layer sparsity:"]},{"cell_type":"markdown","metadata":{},"source":["In[20]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def doWeights(model):\n","    allWeightsByLayer = {}\n","    for layer in model.layers:\n","        if (layer._name).find(\"batch\")!=-1 or len(layer.get_weights())<1:\n","            continue \n","        weights=layer.weights[0].numpy().flatten()  \n","        allWeightsByLayer[layer._name] = weights\n","        print('Layer {}: % of zeros = {}'.format(layer._name,np.sum(weights==0)/np.size(weights)))\n","    labelsW = []\n","    histosW = []\n","    for key in reversed(sorted(allWeightsByLayer.keys())):\n","        labelsW.append(key)\n","        histosW.append(allWeightsByLayer[key])\n","    fig = plt.figure(figsize=(10,10))\n","    bins = np.linspace(-1.5, 1.5, 50)\n","    plt.hist(histosW,bins,histtype='stepfilled',stacked=True,label=labelsW, edgecolor='black')\n","    plt.legend(frameon=False,loc='upper left')\n","    plt.ylabel('Number of Weights')\n","    plt.xlabel('Weights')\n","    plt.figtext(0.2, 0.38,model._name, wrap=True, horizontalalignment='left',verticalalignment='center')\n","    \n","doWeights(model_pruned) \n","doWeights(qmodel_pruned) "]},{"cell_type":"markdown","metadata":{},"source":["We see that 50% of the weights per layer are set to zero, as expected.<br>\n","Now, let's synthesize the floating point Keras model and the QKeras quantized model!"]},{"cell_type":"markdown","metadata":{},"source":["## CNNs in hls4ml<br>\n","<br>\n","In this part, we will take the two models we trained above (the floating-point 32 Keras model and the 6-bit QKeras model), and synthesize them with hls4ml. Although your models are probably already in memory, let's load them from scratch. We need to pass the appropriate custom QKeras/pruning layers when loading, and remove the pruning parameters that were saved together with the model."]},{"cell_type":"markdown","metadata":{},"source":["In[21]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow_model_optimization.sparsity.keras import strip_pruning\n","from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n","from qkeras.utils import _add_supported_quantized_objects"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["co = {}\n","_add_supported_quantized_objects(co)\n","co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = tf.keras.models.load_model('pruned_cnn_model.h5',custom_objects=co)\n","model  = strip_pruning(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["qmodel = tf.keras.models.load_model('quantized_pruned_cnn_model.h5',custom_objects=co)\n","qmodel  = strip_pruning(qmodel)"]},{"cell_type":"markdown","metadata":{},"source":["Now, we need to define the hls4ml and Vivado configurations. Two things will change with respect to what was done in the previous exercises. First, we will use ``IOType= 'io_stream'`` in the Vivado configuration.<br>\n","<br>\n","---<br>\n","****You must use ``IOType= 'io_stream'`` if attempting to synthesize a convolutional neural network.****<br>\n","<br>\n","---<br>\n","The CNN implementation in hls4ml is based on streams, which are synthesized in hardware as first in, first out (FIFO) buffers. Shift registers are used to keep track of the last  ``<kernel height - 1>`` rows of input pixels, and maintains a shifting snapshot of the convolution kernel.<br>\n","<br>\n","This is illustrated  in the gif below. Here, the input image is at the top-left and the output image at the bottom left. The top right image shows the internal state of the shift registers and convolutional kernel. The red square indicates the current pixels contained within the convolutional kernel.<br>\n","<br>\n","![alt text](images/conv2d_animation.gif \"The implementation of convolutional layers in hls4ml.\")<br>\n","<br>\n","Lastly, we will use ``['Strategy'] = 'Latency'`` for all the layers in the hls4ml configuration. If one layer would have >4096 elements, we sould set ``['Strategy'] = 'Resource'`` for that layer, or increase the reuse factor by hand. You can find examples of how to do this below."]},{"cell_type":"markdown","metadata":{},"source":["In[23]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import hls4ml\n","import plotting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n","hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n","hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'"]},{"cell_type":"markdown","metadata":{},"source":["irst, the baseline model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')"]},{"cell_type":"markdown","metadata":{},"source":["Set the precision and reuse factor for the full model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n","hls_config['Model']['ReuseFactor'] = 1"]},{"cell_type":"markdown","metadata":{},"source":["Create an entry for each layer, here you can for instance change the strategy for a layer to 'resource' <br>\n","or increase the reuse factor individually for large layers.<br>\n","In this case, we designed the model to be small enough for a fully parallel implementation <br>\n","so we use the latency strategy and reuse factor of 1 for all layers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for Layer in hls_config['LayerName'].keys():\n","    hls_config['LayerName'][Layer]['Strategy'] = 'Latency'\n","    hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n","#If you want best numerical performance for high-accuray models, while the default latency strategy is faster but numerically more unstable\n","#hls_config['LayerName']['output_softmax']['Strategy'] = 'Stable'\n","plotting.print_dict(hls_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cfg = hls4ml.converters.create_config(backend='Vivado')\n","cfg['IOType']     = 'io_stream' # Must set this if using CNNs!\n","cfg['HLSConfig']  = hls_config\n","cfg['KerasModel'] = model\n","cfg['OutputDir']  = 'pruned_cnn/'\n","cfg['XilinxPart'] = 'xcu250-figd2104-2L-e'\n","  \n","hls_model = hls4ml.converters.keras_to_hls(cfg)\n","hls_model.compile()"]},{"cell_type":"markdown","metadata":{},"source":["Let's get a nice overview over the various shapes and precisions used for each layer through ``hls4ml.utils.plot_model``, as well as look at the weight profile using ``hls4ml.model.profiling.numerical``. The weight profiling returns two plots: Before (top) and after (bottom) various optimizations applied to the HLS model before the final translation to HLS, for instance the fusing of Dense and BatchNormalization layers."]},{"cell_type":"markdown","metadata":{},"source":["In[24]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"]},{"cell_type":"markdown","metadata":{},"source":["In[25]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls4ml.model.profiling.numerical(model=model, hls_model=hls_model)"]},{"cell_type":"markdown","metadata":{},"source":["The colored boxes are the distribution of the weights of the model, and the gray band illustrates the numerical range covered by the chosen fixed point precision. As we configured, this model uses a precision of ``ap_fixed<16,6>`` for all layers of the model. Let's now build our QKeras model"]},{"cell_type":"markdown","metadata":{},"source":["In[27]:"]},{"cell_type":"markdown","metadata":{},"source":["Then the QKeras model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n","hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n","hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls_config_q = hls4ml.utils.config_from_keras_model(qmodel, granularity='name')\n","hls_config_q['Model']['ReuseFactor'] = 1\n","hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n","#hls_config_q['LayerName']['output_softmax']['Strategy'] = 'Stable'\n","plotting.print_dict(hls_config_q)\n","  \n","cfg_q = hls4ml.converters.create_config(backend='Vivado')\n","cfg_q['IOType']     = 'io_stream' # Must set this if using CNNs!\n","cfg_q['HLSConfig']  = hls_config_q\n","cfg_q['KerasModel'] = qmodel\n","cfg_q['OutputDir']  = 'quantized_pruned_cnn/'\n","cfg_q['XilinxPart'] = 'xcu250-figd2104-2L-e'\n","  \n","hls_model_q = hls4ml.converters.keras_to_hls(cfg_q)\n","hls_model_q.compile()"]},{"cell_type":"markdown","metadata":{},"source":["Let's plot the model and profile the weights her too"]},{"cell_type":"markdown","metadata":{},"source":["In[28]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls4ml.model.profiling.numerical(model=qmodel, hls_model=hls_model_q)\n","hls4ml.utils.plot_model(hls_model_q, show_shapes=True, show_precision=True, to_file=None)"]},{"cell_type":"markdown","metadata":{},"source":["For the 6-bit QKeras model, we see that different precisions are used for different layers."]},{"cell_type":"markdown","metadata":{},"source":["### Accuracy with bit-accurate emulation <br>\n","Let's check that the hls4ml accuracy matches the original. This usually takes some time, so let's do it over a reduced dataset"]},{"cell_type":"markdown","metadata":{},"source":["In[30]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_test_reduced = X_test[:300]\n","Y_test_reduced = Y_test[:300]"]},{"cell_type":"markdown","metadata":{},"source":["In[31]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_predict        = model.predict(X_test_reduced)\n","y_predict_hls4ml = hls_model.predict(np.ascontiguousarray(X_test_reduced))"]},{"cell_type":"markdown","metadata":{},"source":["In[27]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_predict_q        = qmodel.predict(X_test_reduced)\n","y_predict_hls4ml_q = hls_model_q.predict(np.ascontiguousarray(X_test_reduced))"]},{"cell_type":"markdown","metadata":{},"source":["In[32]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotting\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plotROC(Y, y_pred, y_pred_hls4ml, label=\"Model\"):\n","    \n","    accuracy_keras  = float(accuracy_score (np.argmax(Y,axis=1), np.argmax(y_pred,axis=1)))\n","    accuracy_hls4ml = float(accuracy_score (np.argmax(Y,axis=1), np.argmax(y_pred_hls4ml,axis=1)))\n","    print(\"Accuracy Keras:  {}\".format(accuracy_keras))\n","    print(\"Accuracy hls4ml: {}\".format(accuracy_hls4ml))\n","    \n","    fig, ax = plt.subplots(figsize=(9, 9))\n","    _ = plotting.makeRoc(Y, y_pred, labels=['%i'%nr for nr in range(n_classes)])\n","    plt.gca().set_prop_cycle(None) # reset the colors\n","    _ = plotting.makeRoc(Y, y_pred_hls4ml, labels=['%i'%nr for nr in range(n_classes)], linestyle='--')\n","    from matplotlib.lines import Line2D\n","    lines = [Line2D([0], [0], ls='-'),\n","             Line2D([0], [0], ls='--')]\n","    from matplotlib.legend import Legend\n","    leg = Legend(ax, lines, labels=['Keras', 'hls4ml'],\n","                loc='lower right', frameon=False)\n","    ax.add_artist(leg)\n","    plt.figtext(0.2, 0.38,label, wrap=True, horizontalalignment='left',verticalalignment='center')\n","    plt.ylim(0.01,1.)\n","    plt.xlim(0.7,1.)"]},{"cell_type":"markdown","metadata":{},"source":["Plot the pruned floating point model:    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plotROC(Y_test_reduced,y_predict,y_predict_hls4ml,label=\"Keras\") "]},{"cell_type":"markdown","metadata":{},"source":["Plot the pruned and quantized QKeras model<br>\n","lotROC(Y_test_reduced,y_predict_q,y_predict_hls4ml_q,label=\"QKeras\") "]},{"cell_type":"markdown","metadata":{},"source":["Looks good! Let's synthesize the models. <br>\n","## Logic synthesis<br>\n","This takes quite a while for CNN models, up to one hour for the models considered here. In the interest of time, we have therefore provided the neccessary reports for the models considered. You can also synthesize them yourself if you have time, and as usual follow the progress using ``tail -f pruned_cnn/vivado_hls.log`` and ``tail -f quantized_pruned_cnn/vivado_hls.log``.<br>\n"]},{"cell_type":"markdown","metadata":{},"source":["In[29]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["synth = False # Only if you want to synthesize the models yourself (>1h per model) rather than look at the provided reports.\n","if synth:\n","    hls_model.build(csim=False, synth=True, vsynth=True)\n","    hls_model_q.build(csim=False, synth=True, vsynth=True)"]},{"cell_type":"markdown","metadata":{},"source":["We extract the latency from the C synthesis, namely the report in ```<project_dir>/myproject_prj/solution1/syn/report/myproject_csynth.rpt```. A more accurate latency estimate can be obtained from running cosim by passing ```hls_model.build(csim=False, synth=True, vsynth=True, cosim=True)``` ( = C/RTL cosimulation, synthesised HLS code is run on a simulator and tested on C test bench) but this takes a lot of time so we will skip it here.<br>\n","The resource estimates are obtained from the Vivado logic synthesis, and can be extracted from the report in ```<project_dir>/vivado_synth.rpt```. Let's fetch the most relevant numbers:"]},{"cell_type":"markdown","metadata":{},"source":["In[30]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def getReports(indir):\n","    data_ = {}\n","    \n","    report_vsynth = Path('{}/vivado_synth.rpt'.format(indir))\n","    report_csynth = Path('{}/myproject_prj/solution1/syn/report/myproject_csynth.rpt'.format(indir))\n","    \n","    if report_vsynth.is_file() and report_csynth.is_file():\n","        print('Found valid vsynth and synth in {}! Fetching numbers'.format(indir))\n","        \n","        # Get the resources from the logic synthesis report \n","        with report_vsynth.open() as report:\n","            lines = np.array(report.readlines())\n","            data_['lut']     = int(lines[np.array(['CLB LUTs*' in line for line in lines])][0].split('|')[2])\n","            data_['ff']      = int(lines[np.array(['CLB Registers' in line for line in lines])][0].split('|')[2])\n","            data_['bram']    = float(lines[np.array(['Block RAM Tile' in line for line in lines])][0].split('|')[2])\n","            data_['dsp']     = int(lines[np.array(['DSPs' in line for line in lines])][0].split('|')[2])\n","            data_['lut_rel'] = float(lines[np.array(['CLB LUTs*' in line for line in lines])][0].split('|')[5])\n","            data_['ff_rel']  = float(lines[np.array(['CLB Registers' in line for line in lines])][0].split('|')[5])\n","            data_['bram_rel']= float(lines[np.array(['Block RAM Tile' in line for line in lines])][0].split('|')[5])\n","            data_['dsp_rel'] = float(lines[np.array(['DSPs' in line for line in lines])][0].split('|')[5])\n","        \n","        with report_csynth.open() as report:\n","            lines = np.array(report.readlines())\n","            lat_line = lines[np.argwhere(np.array(['Latency (cycles)' in line for line in lines])).flatten()[0] + 3]\n","            data_['latency_clks'] = int(lat_line.split('|')[2])\n","            data_['latency_mus']  = float(lat_line.split('|')[2])*5.0/1000.\n","            data_['latency_ii']   = int(lat_line.split('|')[6])\n","    \n","    return data_"]},{"cell_type":"markdown","metadata":{},"source":["In[31]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","import pprint "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_pruned_ref = getReports('pruned_cnn')\n","data_quantized_pruned = getReports('quantized_pruned_cnn')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\n Resource usage and latency: Pruned\")\n","pprint.pprint(data_pruned_ref)\n","print(\"\\n Resource usage and latency: Pruned + quantized\")\n","pprint.pprint(data_quantized_pruned)"]},{"cell_type":"markdown","metadata":{},"source":["We see that the latency is of around 5 microseconds for both the quantized and the unquantized model, but that the resources are signifcantly reduced using QKeras.<br>\n","<br>\n","Congratulations! You have now reached the end of this notebook. If you have some spare time, you can have a look at the bonus exercise below, where you will learn how to perform a bayesian optimization over the QKeras quantizers in order to obtain an optimally heterogeneously quantized model.<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n"]},{"cell_type":"markdown","metadata":{},"source":["# Bonus exercise: Automatic quantization with AutoQKeras<br>\n","<br>\n","In this bonus exercise, you will learn how to find the optimal heterogeneously quantized model using AutoQKeras.<br>\n","For more details, you can look at the [AutoQKeras notebook](https://github.com/google/qkeras/blob/master/notebook/AutoQKeras.ipynb). <br>\n","<br>\n","Let's first check the estimated energy consumption of the QKeras 6-bit model using QTools. By setting ```for_reference=True``` you can print out the unquantized model energy consumption and compare the two. Note that this only works for QKeras layers. "]},{"cell_type":"markdown","metadata":{},"source":["In[32]:"]},{"cell_type":"markdown","metadata":{},"source":["In[33]:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-21 15:38:13.832923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-21 15:38:13.927264: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-02-21 15:38:14.451942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2023-02-21 15:38:14.451989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2023-02-21 15:38:14.451994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["from qkeras import print_qstats\n","# for automatic quantization\n","import pprint\n","from qkeras.autoqkeras import *\n","from qkeras import *\n","from qkeras.utils import model_quantize"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from qkeras.qtools import run_qtools\n","from qkeras.qtools import settings as qtools_settings\n","from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n","from qkeras import quantized_bits\n","from qkeras import QDense, QActivation"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","    \"source_quantizers\": [\n","        {\n","            \"quantizer_type\": \"quantized_bits\",\n","            \"bits\": 16,\n","            \"int_bits\": 6,\n","            \"is_signed\": true\n","        }\n","    ],\n","    \"conv2d\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"quantized_bits\",\n","                \"bits\": 16,\n","                \"int_bits\": 6,\n","                \"is_signed\": true\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                2,\n","                16\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 16\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 14688000\n","    },\n","    \"batch_normalization\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        }\n","    },\n","    \"activation\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 816000\n","    },\n","    \"conv2d_1\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                16,\n","                16\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 16\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 117504000\n","    },\n","    \"batch_normalization_1\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        }\n","    },\n","    \"activation_1\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 816000\n","    },\n","    \"conv2d_2\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                16,\n","                16\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 16\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 117504000\n","    },\n","    \"batch_normalization_2\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        }\n","    },\n","    \"add\": {\n","        \"layer_type\": \"Add\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            },\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"Add_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 816000\n","    },\n","    \"activation_2\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                200,\n","                255,\n","                16\n","            ]\n","        },\n","        \"operation_count\": 816000\n","    },\n","    \"conv2d_3\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                16,\n","                32\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 32\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        },\n","        \"operation_count\": 58982400\n","    },\n","    \"conv2d_5\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                1,\n","                1,\n","                16,\n","                32\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 32\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        },\n","        \"operation_count\": 6553600\n","    },\n","    \"batch_normalization_3\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        }\n","    },\n","    \"activation_3\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        },\n","        \"operation_count\": 409600\n","    },\n","    \"conv2d_4\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                32,\n","                32\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 32\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        },\n","        \"operation_count\": 117964800\n","    },\n","    \"batch_normalization_4\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        }\n","    },\n","    \"add_1\": {\n","        \"layer_type\": \"Add\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            },\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"Add_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        },\n","        \"operation_count\": 409600\n","    },\n","    \"activation_4\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                100,\n","                128,\n","                32\n","            ]\n","        },\n","        \"operation_count\": 409600\n","    },\n","    \"conv2d_6\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                32,\n","                64\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 64\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 58982400\n","    },\n","    \"conv2d_8\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                1,\n","                1,\n","                32,\n","                64\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 64\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 6553600\n","    },\n","    \"batch_normalization_5\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        }\n","    },\n","    \"activation_5\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 204800\n","    },\n","    \"conv2d_7\": {\n","        \"layer_type\": \"Conv2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                3,\n","                3,\n","                64,\n","                64\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 64\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 117964800\n","    },\n","    \"batch_normalization_6\": {\n","        \"layer_type\": \"BatchNormalization\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"gamma_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"beta_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"mean_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"variance_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16\n","        },\n","        \"internal_divide_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"internal_accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        }\n","    },\n","    \"add_2\": {\n","        \"layer_type\": \"Add\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            },\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"Add_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 204800\n","    },\n","    \"activation_6\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                50,\n","                64,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 204800\n","    },\n","    \"average_pooling2d\": {\n","        \"layer_type\": \"AveragePooling2D\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                1,\n","                1,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 160000\n","    },\n","    \"flatten\": {\n","        \"layer_type\": \"Flatten\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                64\n","            ]\n","        },\n","        \"operation_count\": 64\n","    },\n","    \"dense\": {\n","        \"layer_type\": \"Dense\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"weight_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                64,\n","                2\n","            ]\n","        },\n","        \"bias_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": 2\n","        },\n","        \"multiplier\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"mul\"\n","        },\n","        \"accumulator\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"op_type\": \"add\"\n","        },\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                2\n","            ]\n","        },\n","        \"operation_count\": 128\n","    },\n","    \"softmax\": {\n","        \"layer_type\": \"Activation\",\n","        \"input_quantizer_list\": [\n","            {\n","                \"quantizer_type\": \"floating_point\",\n","                \"bits\": 16\n","            }\n","        ],\n","        \"output_quantizer\": {\n","            \"quantizer_type\": \"floating_point\",\n","            \"bits\": 16,\n","            \"shape\": [\n","                -1,\n","                2\n","            ]\n","        },\n","        \"operation_count\": 2\n","    }\n","}\n"]}],"source":["q = run_qtools.QTools(model, \n","                      process=\"horowitz\", \n","                      source_quantizers=[quantized_bits(16, 5, 1)], \n","                      is_inference=True, \n","                      weights_path=None,\n","                      keras_quantizer=\"fp16\",\n","                      keras_accumulator=\"fp16\", \n","                      for_reference=False)\n","q.qtools_stats_print()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["energy_dict = q.pe(\n","    weights_on_memory=\"fixed\",\n","    activations_on_memory=\"fixed\",\n","    min_sram_size=8*16*1024*1024,\n","    rd_wr_on_io=False)"]},{"cell_type":"markdown","metadata":{},"source":["get stats of energy distribution in each layer"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["energy_profile = q.extract_energy_profile(\n","    qtools_settings.cfg.include_energy, energy_dict)\n","# extract sum of energy of each layer according to the rule specified in\n","# qtools_settings.cfg.include_energy\n","total_energy = q.extract_energy_sum(\n","    qtools_settings.cfg.include_energy, energy_dict)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'activation': {'energy': {'inputs': 0.0,\n","                           'op_cost': 0.0,\n","                           'outputs': 0.0,\n","                           'parameters': 0.0},\n","                'total': 0.0},\n"," 'activation_1': {'energy': {'inputs': 0.0,\n","                             'op_cost': 0.0,\n","                             'outputs': 0.0,\n","                             'parameters': 0.0},\n","                  'total': 0.0},\n"," 'activation_2': {'energy': {'inputs': 0.0,\n","                             'op_cost': 0.0,\n","                             'outputs': 0.0,\n","                             'parameters': 0.0},\n","                  'total': 0.0},\n"," 'activation_3': {'energy': {'inputs': 0.0,\n","                             'op_cost': 0.0,\n","                             'outputs': 0.0,\n","                             'parameters': 0.0},\n","                  'total': 0.0},\n"," 'activation_4': {'energy': {'inputs': 0.0,\n","                             'op_cost': 0.0,\n","                             'outputs': 0.0,\n","                             'parameters': 0.0},\n","                  'total': 0.0},\n"," 'activation_5': {'energy': {'inputs': 0.0,\n","                             'op_cost': 0.0,\n","                             'outputs': 0.0,\n","                             'parameters': 0.0},\n","                  'total': 0.0},\n"," 'activation_6': {'energy': {'inputs': 0.0,\n","                             'op_cost': 0.0,\n","                             'outputs': 0.0,\n","                             'parameters': 0.0},\n","                  'total': 0.0},\n"," 'add': {'energy': {'inputs': 0.0,\n","                    'op_cost': 326400.0,\n","                    'outputs': 0.0,\n","                    'parameters': 0.0},\n","         'total': 326400.0},\n"," 'add_1': {'energy': {'inputs': 0.0,\n","                      'op_cost': 163840.0,\n","                      'outputs': 0.0,\n","                      'parameters': 0.0},\n","           'total': 163840.0},\n"," 'add_2': {'energy': {'inputs': 0.0,\n","                      'op_cost': 81920.0,\n","                      'outputs': 0.0,\n","                      'parameters': 0.0},\n","           'total': 81920.0},\n"," 'average_pooling2d': {'energy': {'inputs': 0.0,\n","                                  'op_cost': 64000.0,\n","                                  'outputs': 0.0,\n","                                  'parameters': 0.0},\n","                       'total': 64000.0},\n"," 'batch_normalization': {'energy': {'inputs': 0.0,\n","                                    'op_cost': 1795200.0,\n","                                    'outputs': 0.0,\n","                                    'parameters': 0.0},\n","                         'total': 0.0},\n"," 'batch_normalization_1': {'energy': {'inputs': 0.0,\n","                                      'op_cost': 1795200.0,\n","                                      'outputs': 0.0,\n","                                      'parameters': 0.0},\n","                           'total': 0.0},\n"," 'batch_normalization_2': {'energy': {'inputs': 0.0,\n","                                      'op_cost': 1795200.0,\n","                                      'outputs': 0.0,\n","                                      'parameters': 0.0},\n","                           'total': 0.0},\n"," 'batch_normalization_3': {'energy': {'inputs': 0.0,\n","                                      'op_cost': 901120.0,\n","                                      'outputs': 0.0,\n","                                      'parameters': 0.0},\n","                           'total': 0.0},\n"," 'batch_normalization_4': {'energy': {'inputs': 0.0,\n","                                      'op_cost': 901120.0,\n","                                      'outputs': 0.0,\n","                                      'parameters': 0.0},\n","                           'total': 0.0},\n"," 'batch_normalization_5': {'energy': {'inputs': 0.0,\n","                                      'op_cost': 450560.0,\n","                                      'outputs': 0.0,\n","                                      'parameters': 0.0},\n","                           'total': 0.0},\n"," 'batch_normalization_6': {'energy': {'inputs': 0.0,\n","                                      'op_cost': 450560.0,\n","                                      'outputs': 0.0,\n","                                      'parameters': 0.0},\n","                           'total': 0.0},\n"," 'conv2d': {'energy': {'inputs': 96996.64,\n","                       'op_cost': 22032000.0,\n","                       'outputs': 0.0,\n","                       'parameters': 0.0},\n","            'total': 22128996.64},\n"," 'conv2d_1': {'energy': {'inputs': 0.0,\n","                         'op_cost': 176256000.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 176256000.0},\n"," 'conv2d_2': {'energy': {'inputs': 0.0,\n","                         'op_cost': 176256000.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 176256000.0},\n"," 'conv2d_3': {'energy': {'inputs': 0.0,\n","                         'op_cost': 88473600.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 88473600.0},\n"," 'conv2d_4': {'energy': {'inputs': 0.0,\n","                         'op_cost': 176947200.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 176947200.0},\n"," 'conv2d_5': {'energy': {'inputs': 0.0,\n","                         'op_cost': 9830400.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 9830400.0},\n"," 'conv2d_6': {'energy': {'inputs': 0.0,\n","                         'op_cost': 88473600.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 88473600.0},\n"," 'conv2d_7': {'energy': {'inputs': 0.0,\n","                         'op_cost': 176947200.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 176947200.0},\n"," 'conv2d_8': {'energy': {'inputs': 0.0,\n","                         'op_cost': 9830400.0,\n","                         'outputs': 0.0,\n","                         'parameters': 0.0},\n","              'total': 9830400.0},\n"," 'dense': {'energy': {'inputs': 0.0,\n","                      'op_cost': 192.0,\n","                      'outputs': 0.0,\n","                      'parameters': 0.0},\n","           'total': 192.0},\n"," 'flatten': {'energy': {'inputs': 0.0,\n","                        'op_cost': 0.0,\n","                        'outputs': 0.0,\n","                        'parameters': 0.0},\n","             'total': 0.0},\n"," 'softmax': {'energy': {'inputs': 0.0,\n","                        'op_cost': 0.0,\n","                        'outputs': 3.8,\n","                        'parameters': 0.0},\n","             'total': 3.8}}\n","\n"]}],"source":["pprint.pprint(energy_profile)\n","print()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total energy: 925.779752 uJ\n"]}],"source":["print(\"Total energy: {:.6f} uJ\".format(total_energy / 1000000.0))"]},{"cell_type":"markdown","metadata":{},"source":["Now, lets use AutoQKeras to find an optimally heterogeneously quantized model for us. For more details, check the AutoQKeras tutorial linked above. As baseline model, we'll use the pruned floating point Keras model from above."]},{"cell_type":"markdown","metadata":{},"source":["In[34]:"]},{"cell_type":"markdown","metadata":{},"source":["These are the quantizers we'll test in the bayesian optimization"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["quantization_config = {\n","        \"kernel\": {\n","                \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n","                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n","                \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n","                \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n","        },\n","        \"bias\": {\n","                \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n","                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n","                \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n","                \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n","        },\n","        \"activation\": {\n","                \"quantized_relu(3,1)\": 3,\n","                \"quantized_relu(4,2)\": 4,\n","                \"quantized_relu(8,2)\": 8,\n","                \"quantized_relu(8,4)\": 8,\n","                \"quantized_relu(16,6)\": 16\n","        },\n","        \"linear\": {\n","                \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n","                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n","                \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n","                \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n","        }\n","}"]},{"cell_type":"markdown","metadata":{},"source":["These are the layer types we will quantize"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["limit = {\n","    \"Dense\": [8, 8, 16],\n","    \"Conv2D\": [8, 8, 16],\n","    \"Activation\": [16],\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Use this if you want to minimize the model bit size"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["goal_bits = {\n","    \"type\": \"bits\",\n","          \"params\": {\n","              \"delta_p\": 8.0, # We tolerate up to a +8% accuracy change\n","              \"delta_n\": 8.0, # We tolerate down to a -8% accuracy change\n","              \"rate\": 2.0,    # We want a x2 times smaller model\n","              \"stress\": 1.0,  # Force the reference model size to be smaller by setting stress<1\n","              \"input_bits\": 8,\n","              \"output_bits\": 8,\n","              \"ref_bits\": 8,\n","              \"config\": {\n","                  \"default\": [\"parameters\", \"activations\"]\n","              }\n","          }\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Use this if you want to minimize the model energy consumption"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["goal_energy = {\n","    \"type\": \"energy\",\n","    \"params\": {\n","        \"delta_p\": 8.0,\n","        \"delta_n\": 8.0,\n","        \"rate\": 2.0,\n","        \"stress\": 1.0,\n","        \"process\": \"horowitz\",\n","        \"parameters_on_memory\": [\"sram\", \"sram\"],\n","        \"activations_on_memory\": [\"sram\", \"sram\"],\n","        \"rd_wr_on_io\": [False, False],\n","        \"min_sram_size\": [0, 0],\n","        \"source_quantizers\": [\"fp32\"],\n","        \"reference_internal\": \"int8\",\n","        \"reference_accumulator\": \"int32\"\n","        }\n","}"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["run_config = {\n","        \"goal\": goal_energy,\n","        \"quantization_config\": quantization_config,\n","        \"learning_rate_optimizer\": False,\n","        \"transfer_weights\": False, # Randomely initialize weights\n","        \"mode\": \"bayesian\", # This can be bayesian,random,hyperband\n","        \"seed\": 42,\n","        \"limit\": limit,\n","        \"tune_filters\": \"layer\",\n","        \"tune_filters_exceptions\": \"^output\",\n","        \"distribution_strategy\": None,\n","        \"max_trials\": 5 # Let's just do 5 trials for this demonstrator, ideally you should do as many as possible\n","}"]},{"cell_type":"markdown","metadata":{},"source":["In[36]:"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from qkeras.autoqkeras import AutoQKeras"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Limit configuration:{\"Dense\": [8, 8, 16], \"Conv2D\": [8, 8, 16], \"Activation\": [16]}\n"]},{"name":"stderr","output_type":"stream","text":["/home/zel032/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'lr'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoqk \u001b[39m=\u001b[39m AutoQKeras(model, output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mautoq_cnn\u001b[39;49m\u001b[39m\"\u001b[39;49m, metrics\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39macc\u001b[39;49m\u001b[39m\"\u001b[39;49m], custom_objects\u001b[39m=\u001b[39;49m{}, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_config)\n\u001b[1;32m      2\u001b[0m autoqk\u001b[39m.\u001b[39mfit(train_data, validation_data\u001b[39m=\u001b[39mval_data, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/qkeras/autoqkeras/autoqkeras_internal.py:876\u001b[0m, in \u001b[0;36mAutoQKeras.__init__\u001b[0;34m(self, model, metrics, custom_objects, goal, output_dir, mode, custom_tuner, transfer_weights, frozen_layers, activation_bits, limit, tune_filters, tune_filters_exceptions, learning_rate_optimizer, layer_indexes, quantization_config, overwrite, head_name, score_metric, **tuner_kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtuner \u001b[39m=\u001b[39m RandomSearch(\n\u001b[1;32m    871\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel,\n\u001b[1;32m    872\u001b[0m       objective\u001b[39m=\u001b[39mkt\u001b[39m.\u001b[39mObjective(score_metric, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    873\u001b[0m       project_name\u001b[39m=\u001b[39moutput_dir,\n\u001b[1;32m    874\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtuner_kwargs)\n\u001b[1;32m    875\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbayesian\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtuner \u001b[39m=\u001b[39m BayesianOptimization(\n\u001b[1;32m    877\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel,\n\u001b[1;32m    878\u001b[0m       objective\u001b[39m=\u001b[39;49mkt\u001b[39m.\u001b[39;49mObjective(score_metric, \u001b[39m\"\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    879\u001b[0m       project_name\u001b[39m=\u001b[39;49moutput_dir,\n\u001b[1;32m    880\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtuner_kwargs)\n\u001b[1;32m    881\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhyperband\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    882\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtuner \u001b[39m=\u001b[39m Hyperband(\n\u001b[1;32m    883\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel,\n\u001b[1;32m    884\u001b[0m       objective\u001b[39m=\u001b[39mkt\u001b[39m.\u001b[39mObjective(score_metric, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    885\u001b[0m       project_name\u001b[39m=\u001b[39moutput_dir,\n\u001b[1;32m    886\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtuner_kwargs)\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras_tuner/tuners/bayesian.py:387\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    359\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    360\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    373\u001b[0m ):\n\u001b[1;32m    374\u001b[0m     oracle \u001b[39m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    375\u001b[0m         objective\u001b[39m=\u001b[39mobjective,\n\u001b[1;32m    376\u001b[0m         max_trials\u001b[39m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m         max_consecutive_failed_trials\u001b[39m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    386\u001b[0m     )\n\u001b[0;32m--> 387\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(oracle\u001b[39m=\u001b[39;49moracle, hypermodel\u001b[39m=\u001b[39;49mhypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:113\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[1;32m    106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[0;32m--> 113\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    114\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[1;32m    115\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[1;32m    116\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[1;32m    117\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[1;32m    118\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m    119\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[1;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:120\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreload()\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[1;32m    122\u001b[0m \u001b[39m# Run in distributed mode.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m dist_utils\u001b[39m.\u001b[39mis_chief_oracle():\n\u001b[1;32m    124\u001b[0m     \u001b[39m# Blocks forever.\u001b[39;00m\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:184\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[1;32m    183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_activate_all_conditions()\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:141\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m hp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_space()\n\u001b[1;32m    140\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Update the recorded scopes.\u001b[39;00m\n","File \u001b[0;32m~/software/miniconda3/envs/hls4ml/lib/python3.8/site-packages/qkeras/autoqkeras/autoqkeras_internal.py:633\u001b[0m, in \u001b[0;36mAutoQKHyperModel.build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    629\u001b[0m delta_lr \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m+\u001b[39m (total_factor \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m total_factor\n\u001b[1;32m    631\u001b[0m \u001b[39m# we assume model has been compiled at least.\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mlr\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    635\u001b[0m \u001b[39m# we assume that delta_lr can lower lr to accommodate\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[39m# for more quantization\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m# if learning rate scheduler is used, we assume the callback to manage\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[39m# learning rate. Just set it to constant.\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate_optimizer:\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lr'"]}],"source":["autoqk = AutoQKeras(model, output_dir=\"autoq_cnn\", metrics=[\"acc\"], custom_objects={}, **run_config)\n","autoqk.fit(train_data, validation_data=val_data, epochs=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["aqmodel = autoqk.get_best_model()\n","print_qmodel_summary(aqmodel)   "]},{"cell_type":"markdown","metadata":{},"source":["Train for the full epochs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["callbacks = [\n","            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n","            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n","            ]  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start = time.time()\n","history = aqmodel.fit(train_data,\n","                      epochs = n_epochs,\n","                      validation_data = val_data,\n","                      callbacks = callbacks, \n","                      verbose=1)     \n","end = time.time()\n","print('\\n It took {} minutes to train!\\n'.format( (end - start)/60.))"]},{"cell_type":"markdown","metadata":{},"source":["In[37]:"]},{"cell_type":"markdown","metadata":{},"source":["This model has some remnants from the optimization procedure attached to it, so let's define a new one"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["aqmodel.save_weights(\"autoqkeras_cnn_weights.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["layers = [l for l in aqmodel.layers]\n","x = layers[0].output\n","for i in range(1, len(layers)):\n","    x = layers[i](x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model = Model(inputs=[layers[0].input], outputs=[x])   \n","LOSS        = tf.keras.losses.BinaryCrossentropy()\n","OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n","new_model.summary()\n","new_model.load_weights(\"autoqkeras_cnn_weights.h5\")\n","print_qmodel_summary(new_model)  "]},{"cell_type":"markdown","metadata":{},"source":["Let's check what the best heterogeneously quantized model looks like (keep in mind we only did a few trials, the optimization obviosuly didn't have time to converge at the minimum but yo get the idea!)"]},{"cell_type":"markdown","metadata":{},"source":["In[38]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n","hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n","hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hls_config_aq = hls4ml.utils.config_from_keras_model(new_model, granularity='name')\n","hls_config_aq['Model']['ReuseFactor'] = 1\n","hls_config_aq['Model']['Precision'] = 'ap_fixed<16,6>'\n","hls_config_aq['LayerName']['output_softmax']['Strategy'] = 'Stable'\n","plotting.print_dict(hls_config_aq)\n","  \n","cfg_aq = hls4ml.converters.create_config(backend='Vivado')\n","cfg_aq['IOType']     = 'io_stream' # Must set this if using CNNs!\n","cfg_aq['HLSConfig']  = hls_config_aq\n","cfg_aq['KerasModel'] = new_model\n","cfg_aq['OutputDir']  = 'autoqkeras_cnn/'\n","cfg_aq['XilinxPart'] = 'xcu250-figd2104-2L-e'\n","  \n","hls_model_aq = hls4ml.converters.keras_to_hls(cfg_aq)\n","hls_model_aq.compile()"]},{"cell_type":"markdown","metadata":{},"source":["In[40]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_predict_aq        = aqmodel.predict(X_test_reduced)\n","y_predict_hls4ml_aq = hls_model_aq.predict(np.ascontiguousarray(X_test_reduced))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy_keras  = float(accuracy_score (np.argmax(Y_test_reduced,axis=1), np.argmax(y_predict_aq,axis=1)))\n","accuracy_hls4ml = float(accuracy_score (np.argmax(Y_test_reduced,axis=1), np.argmax(y_predict_hls4ml_aq,axis=1)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Accuracy AutoQ Keras:  {}\".format(accuracy_keras))\n","print(\"Accuracy AutoQ hls4ml: {}\".format(accuracy_hls4ml))\n","    "]},{"cell_type":"markdown","metadata":{},"source":["The accuracy is slightly lower for this heterogeneously quantized model. Due to some randomness in the optimization procedure, you're going to have to synthesize this one yourself!"]},{"cell_type":"markdown","metadata":{},"source":["In[41]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["synth = False\n","if synth:\n","    hls_model_aq.build(csim=False, synth=True, vsynth=True)\n","    data_autoq = getReports('autoq_cnn')\n","    print(\"\\n Resource usage and latency: AutoQ\")\n","    pprint.pprint(data_autoq)"]},{"cell_type":"markdown","metadata":{},"source":["In[ ]:"]}],"metadata":{"kernelspec":{"display_name":"hls4ml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"3883d520cb54f8a9aa58a406bbec063a51b7ebff2d87db09f120055b14978cef"}}},"nbformat":4,"nbformat_minor":2}
