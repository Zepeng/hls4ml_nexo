# -*- coding: utf-8 -*-
"""Creating a tf.data.Dataset from a DataGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pH9NKhAHT40ygOOf4bwld8j221r9SRq_
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import h5py

class nEXODataset:
    def __init__(self, phase, h5_path, csv_path, transformations = None):
        #super().__init__()
        csv_info = pd.read_csv(csv_path, skiprows=1, header=None)
        self.groupname = np.asarray(csv_info.iloc[:,0])
        self.datainfo = np.asarray(csv_info.iloc[:,1])
        self.h5file = h5py.File(h5_path, 'r')
        #self.normalize = transforms.Normalize(mean, std)
        self.transforms = transformations

    def __len__(self):
        return self.datainfo.shape[0]

    def __getitem__(self,idx):
        dset_entry = self.h5file[self.groupname[idx]][self.datainfo[idx]]
        eventtype = 1 if dset_entry.attrs[u'tag']=='e-' else 0
        x = np.array(dset_entry)[:,:,:]
        indices = np.where(x == 0)
        x = x - np.min(x)
        if np.max(x) > 0:
            x = x/np.max(x)
        #x = x*256. #/np.max(x)
        #x = x.astype(np.uint8)
        y = eventtype #.astype(np.int64)
        x[indices] = 0
        return x, y #tf.one_hot(tf.squeeze(y), 2)
    
    def __call__(self):
        for i in range(self.__len__()):
            yield self.__getitem__(i)
            
            #if i == self.__len__()-1:
            #    self.on_epoch_end()
    
            
    #shuffles the dataset at the end of each epoch
    #def on_epoch_end(self):
    #    reidx = random.sample(population = list(range(self.__len__())),k = self.__len__())
    #    self.imgarr = self.imgarr[reidx]
    #    self.labels = self.labels[reidx]
    #applies randomly selected augmentations to each clip (same for each frame in the clip)
    def augment(self, x):
        if self.transforms is not None:
            x = self.transforms(x)
        x = self.normalize(x)
        return x

import numpy as np
import os, requests, copy, random
import matplotlib.pyplot as plt
from tensorflow.data import Dataset
def test():
    csv_file = '/scratch/zel032/DatasetFromMin/nexo.csv' 
    h5file = '/scratch/zel032/DatasetFromMin/nexo.h5' 
    dg = nEXODataset('train',h5file,csv_file)

    ds = Dataset.from_generator(dg, output_types = (tf.uint8, tf.int64), output_shapes = (tf.TensorShape([200,255,2]),tf.TensorShape([])))
    ds = ds.interleave(lambda x, y: tf.data.Dataset.from_tensors((x,y)), cycle_length=4, block_length=16).batch(32)

    iterator = iter(ds)
    x, y = next(iterator)
    print(x.shape)
    for b in ds:
        imgs, labs = b
        print(imgs.shape, labs.shape)
        fig, axs = plt.subplots(2,2)
        for i in range(2):
            for j in range(2):
                print(imgs[i*4+j])
                img = np.zeros((200, 255, 3))
                img[:, :, :2] = imgs[i*4+j]
                axs[i,j].imshow(img,cmap = 'gray')
        plt.savefig('dataloader.pdf')
        break
if __name__ == '__main__':
    test()
