# -*- coding: utf-8 -*-
"""Creating a tf.data.Dataset from a DataGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pH9NKhAHT40ygOOf4bwld8j221r9SRq_
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import h5py

class nEXODataset:
    def __init__(self, phase, h5_path, csv_path, transformations = None):
        #super().__init__()
        csv_info = pd.read_csv(csv_path, skiprows=1, header=None)
        self.groupname = np.asarray(csv_info.iloc[:,0])
        self.datainfo = np.asarray(csv_info.iloc[:,1])
        self.h5file = h5py.File(h5_path, 'r')
        #self.normalize = transforms.Normalize(mean, std)
        self.transforms = transformations

    def __len__(self):
        return self.datainfo.shape[0]

    def __getitem__(self,idx):
        dset_entry = self.h5file[self.groupname[idx]][self.datainfo[idx]]
        eventtype = 1 if dset_entry.attrs[u'tag']=='e-' else 0
        x = np.array(dset_entry)[:,:,:]
        #x = np.transpose(img, (2,0,1)) 
        arr_padded = np.pad(x, ((0, 0), (0, 0), (0, 1)), 'constant')
        x = arr_padded.reshape(200, 255, 3)
        y = eventtype #.astype(np.int64)
        return x, y
    
    def __call__(self):
        for i in range(self.__len__()):
            yield self.__getitem__(i)
            
            #if i == self.__len__()-1:
            #    self.on_epoch_end()
    
            
    #shuffles the dataset at the end of each epoch
    #def on_epoch_end(self):
    #    reidx = random.sample(population = list(range(self.__len__())),k = self.__len__())
    #    self.imgarr = self.imgarr[reidx]
    #    self.labels = self.labels[reidx]
    #applies randomly selected augmentations to each clip (same for each frame in the clip)
    def augment(self, x):
        if self.transforms is not None:
            x = self.transforms(x)
        x = self.normalize(x)
        return x

#array = np.random.random((1000,32,32,3))
#labels = np.random.randint(0,10,1000)
#print(array.shape, labels.shape)
#mean = np.mean(array, axis = 0)
#std = np.std(array, axis = 0)

import numpy as np
import os, requests, copy, random
#import matplotlib.pyplot as plt
from tensorflow.data import Dataset
def test():
    csv_file = '/scratch/zel032/DatasetFromMin/nexo.csv' 
    h5file = '/scratch/zel032/DatasetFromMin/nexo.h5'
    dg = nEXODataset('train',h5file,csv_file)

    ds = Dataset.from_generator(dg, output_types = (tf.float32, tf.int64), output_shapes = (tf.TensorShape([200,255,3]),tf.TensorShape([])))

    ds = ds.batch(32)

    for b in ds:
        imgs, labs = b
        print(imgs.shape, labs.shape)
        #fig, axs = plt.subplots(8,4)
        #for i in range(8):
        #    for j in range(4):
        #        axs[i,j].imshow(imgs[i*4+j],cmap = 'gray')
        #plt.show()
        break
if __name__ == '__main__':
    test()
